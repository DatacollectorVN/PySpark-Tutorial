{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row, SQLContext, SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/Cellar/apache-spark/3.2.1/libexec/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/17 15:46:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Execute SQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. `createOrReplaceTemp` method\n",
    "`createOrReplaceTemp`: create the temporary table or view for query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = os.path.join('..', 'src-data', 'walmart_stock.csv')\n",
    "schema_1 = spark.read.option('header', True).csv(csv_file_path)\n",
    "schema_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_1.createOrReplaceTempView('walmart_stock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. `spark.sql(<query>)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SELECT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT Date, Volume FROM walmart_stock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2012-01-03|12668800|\n",
      "|2012-01-04| 9593300|\n",
      "|2012-01-05|12768200|\n",
      "|2012-01-06| 8069400|\n",
      "|2012-01-09| 6679300|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result_1 = spark.sql(query)\n",
    "query_result_1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WHERE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT Date, Volume FROM walmart_stock WHERE Volume >= 9000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2012-01-03|12668800|\n",
      "|2012-01-04| 9593300|\n",
      "|2012-01-05|12768200|\n",
      "|2012-01-19| 9234600|\n",
      "|2012-01-20|10378800|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result_2 = spark.sql(query)\n",
    "query_result_2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use with `SUBSTRING(<col_name>, <position>, <length>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT SUBSTRING(Date, 0, 4) AS Year, Volume FROM walmart_stock WHERE Volume >= 9000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Year|  Volume|\n",
      "+----+--------+\n",
      "|2012|12668800|\n",
      "|2012| 9593300|\n",
      "|2012|12768200|\n",
      "|2012| 9234600|\n",
      "|2012|10378800|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result_3 = spark.sql(query)\n",
    "query_result_3.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare SQL vs DataFrame API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2012-01-03|12668800|\n",
      "|2012-01-04| 9593300|\n",
      "|2012-01-05|12768200|\n",
      "|2012-01-06| 8069400|\n",
      "|2012-01-09| 6679300|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_1.select(['Date', 'Volume']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2012-01-03|12668800|\n",
      "|2012-01-04| 9593300|\n",
      "|2012-01-05|12768200|\n",
      "|2012-01-06| 8069400|\n",
      "|2012-01-09| 6679300|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT Date, Volume FROM walmart_stock'\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2012-01-03|12668800|\n",
      "|2012-01-04| 9593300|\n",
      "|2012-01-05|12768200|\n",
      "|2012-01-19| 9234600|\n",
      "|2012-01-20|10378800|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_1.where(schema_1.Volume > 9000000).select(['Date', 'Volume']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2012-01-03|12668800|\n",
      "|2012-01-04| 9593300|\n",
      "|2012-01-05|12768200|\n",
      "|2012-01-19| 9234600|\n",
      "|2012-01-20|10378800|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT Date, Volume FROM walmart_stock WHERE Volume >= 9000000'\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2013-01-02|10390800|\n",
      "|2013-01-03| 8910100|\n",
      "|2013-01-04| 6438000|\n",
      "|2013-01-07| 6201400|\n",
      "|2013-01-08| 5866900|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_1.where(schema_1.Date.like('2013%')).select(['Date', 'Volume']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2013-01-02|10390800|\n",
      "|2013-01-03| 8910100|\n",
      "|2013-01-04| 6438000|\n",
      "|2013-01-07| 6201400|\n",
      "|2013-01-08| 5866900|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT Date, Volume FROM walmart_stock WHERE Date LIKE \"2013%\"'\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+----+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|year|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+----+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|2012|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|2012|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|2012|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|2012|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|2012|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "schema_1.withColumn('year', substring('Date', pos = 0, len = 4)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Year|  Volume|\n",
      "+----+--------+\n",
      "|2012|12668800|\n",
      "|2012| 9593300|\n",
      "|2012|12768200|\n",
      "|2012| 9234600|\n",
      "|2012|10378800|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT SUBSTRING(Date, 0, 4) AS Year, Volume FROM walmart_stock WHERE Volume >= 9000000'\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e8b2dc75a532c1b8be16e00f9f13abc240a1ac4ad83b862d6ae36ef062a2a95"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
