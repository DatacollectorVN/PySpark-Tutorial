{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6cb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b90c8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/06 14:09:31 WARN Utils: Your hostname, Nathans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.247.137.235 instead (on interface en0)\n",
      "22/05/06 14:09:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/Cellar/apache-spark/3.2.1/libexec/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/06 14:09:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0bcf7",
   "metadata": {},
   "source": [
    "### 0. Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f366e",
   "metadata": {},
   "source": [
    "- Real dataset regularly is `key-value` format.\n",
    "- Each row is key that maps to one or many values.\n",
    "- In Pair Rdd: `key` is `indetifier` and `value` is `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f53a1",
   "metadata": {},
   "source": [
    "### 1. Create RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf172c14",
   "metadata": {},
   "source": [
    "#### 1.1. Pair RDDs from key-value tuple list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d2a293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID001', 'Nathan Ngo'), ('ID002', 'Elon Musk'), ('ID003', 'Jisoo')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_val_tup_lst = [('ID001', 'Nathan Ngo'), ('ID002', 'Elon Musk'), ('ID003', 'Jisoo')]\n",
    "pairRDD_tup = sc.parallelize(key_val_tup_lst)\n",
    "pairRDD_tup.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2721b3",
   "metadata": {},
   "source": [
    "#### 1.2. Pair RDDs from other RDDs\n",
    "Use `map` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3591609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID001', 'Nathan Ngo'), ('ID002', 'Elon Musk'), ('ID003', 'Jisoo')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD = sc.parallelize([['ID001', 'Nathan Ngo'], ['ID002', 'Elon Musk'], ['ID003', 'Jisoo']])\n",
    "pairRDD_tup = RDD.map(lambda x: (x[0], x[1])) \n",
    "pairRDD_tup.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774a7f9",
   "metadata": {},
   "source": [
    "### 2. Transformation on Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6625838",
   "metadata": {},
   "source": [
    "- All transformations on RDDs can run on Pair RDDs.\n",
    "- Passing funtion on pari `key-value`.\n",
    "\n",
    "Some speical transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da7405",
   "metadata": {},
   "source": [
    "#### 2.1. Transformation - reduceByKey()\n",
    "`reduceByKey()`: Operate values with the same key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37fa3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID003 with total score is 20\n",
      "ID002 with total score is 16\n",
      "ID001 with total score is 17\n"
     ]
    }
   ],
   "source": [
    "PairRDD_1 = sc.parallelize([('ID001', 8), ('ID002', 9), ('ID003', 10), \n",
    "                           ('ID001', 9), ('ID002', 7), ('ID003', 10)])\n",
    "PairRDD_1_reduce = PairRDD_1.reduceByKey(lambda x, y: x + y)\n",
    "for pair in PairRDD_1_reduce.collect():\n",
    "    print(f'{pair[0]} with total score is {pair[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a0f56",
   "metadata": {},
   "source": [
    "Sort RDD by `sortByKey()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e87991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID001 with total score is 17\n",
      "ID002 with total score is 16\n",
      "ID003 with total score is 20\n"
     ]
    }
   ],
   "source": [
    "PairRDD_1_reduce_sort = PairRDD_1_reduce.sortByKey(ascending=True)\n",
    "for pair in PairRDD_1_reduce_sort.collect():\n",
    "    print(f'{pair[0]} with total score is {pair[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6429d7",
   "metadata": {},
   "source": [
    "#### 2.2. Transformation - groupByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c0924",
   "metadata": {},
   "source": [
    "`groupByKey()`: Group values with the same key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13279631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[54] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PairRDD_1.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60c4d118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID003', <pyspark.resultiterable.ResultIterable at 0x10a7e4a60>),\n",
       " ('ID002', <pyspark.resultiterable.ResultIterable at 0x10a7e4b50>),\n",
       " ('ID001', <pyspark.resultiterable.ResultIterable at 0x10a7e4be0>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PairRDD_1.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c758b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID003 [10, 10]\n",
      "ID002 [9, 7]\n",
      "ID001 [8, 9]\n"
     ]
    }
   ],
   "source": [
    "PairRDD_1_groupby = PairRDD_1.groupByKey().collect()\n",
    "for id_, score in PairRDD_1_groupby:\n",
    "    print(id_, list(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3176f",
   "metadata": {},
   "source": [
    "#### 2.3. Transformation - join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b929014",
   "metadata": {},
   "source": [
    "`PairRDD_1.join(PairRDD_2)`: Concatenate 2 RDD according to keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "876b9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_val_tup_lst = [('ID001', 'Nathan Ngo'), ('ID002', 'Elon Musk'), ('ID003', 'Jisoo')]\n",
    "pairRDD_1 = sc.parallelize(key_val_tup_lst)\n",
    "pairRDD_2 = sc.parallelize([('ID001', 8), ('ID002', 9), ('ID003', 10), \n",
    "                           ('ID001', 9), ('ID002', 7), ('ID003', 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16f35f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID003', ('Jisoo', 10)),\n",
       " ('ID003', ('Jisoo', 10)),\n",
       " ('ID002', ('Elon Musk', 9)),\n",
       " ('ID002', ('Elon Musk', 7)),\n",
       " ('ID001', ('Nathan Ngo', 8)),\n",
       " ('ID001', ('Nathan Ngo', 9))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD_join = pairRDD_1.join(pairRDD_2)\n",
    "pairRDD_join.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0242ec6",
   "metadata": {},
   "source": [
    "### 3. Action on Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b844237",
   "metadata": {},
   "source": [
    "- RDD's actions can apply for Pair RDDs.\n",
    "Some RDD action work for `key-value`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209bcd3",
   "metadata": {},
   "source": [
    "#### 3.1. Action - countByKey()\n",
    "`countByKey()`: return number of total value for each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1cd489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID001 2\n",
      "ID002 2\n",
      "ID003 3\n"
     ]
    }
   ],
   "source": [
    "pairRDD_3 = sc.parallelize([('ID001', 8), ('ID002', 9), ('ID003', 10), \n",
    "                           ('ID001', 9), ('ID002', 7), ('ID003', 10), ('ID003', 9)])\n",
    "\n",
    "for key, val in pairRDD_3.countByKey().items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd330d80",
   "metadata": {},
   "source": [
    "#### 3.2. Action - collectAsMap()\n",
    "`collectAsMap()`: return the last key-value, duplicate key will not be returned, only the last pair will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "441739b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID001': 9, 'ID002': 7, 'ID003': 9}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD_3.collectAsMap()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
